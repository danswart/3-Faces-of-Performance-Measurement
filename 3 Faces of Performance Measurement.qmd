---
title: "3 Faces of Performance Measurement"
subtitle: ""
author: "Dan Swart"
date: "2025-04-29"
# bibliography: manual-refs.bib
format:
  html:
    code-copy: true
    include-after-body: 
      - text: |
         <script type="text/javascript" src="reference-backlinks.js"></script>
    css: 
      - swart.css
    page-layout: full
    fig-width: 12
    fig-height: 10
    fig-dpi: 300
    df-print: paged
    code-overflow: wrap
    toc: true
    citeproc: true
    link-citations: true
  typst:
    fig-width: 12
    fig-height: 10
    fig-dpi: 300
    margin:
      x: 1in
      y: 1in
    toc: true
    fontsize: 14pt
    mainfont: "Latin Modern Roman"
execute:
  echo: false
  message: false
  warning: false
  eval: true
  fig-width: 12
  fig-height: 10

---

```{r}
#| label: setup
#| include: false


knitr::opts_chunk$set(echo = TRUE)

# Prevent scientific notation globally
options(scipen = 999)

# load libraries
library(tidyverse)
library(DT)
library(plotly)
library(ggplot2)
library(kableExtra)
library(tibble)
library(patchwork)
library(ppcor)
library(ggdag)
library(ggplot2)
library(corrplot)
library(ggcorrplot)
library(car)
library(WRS2)
library(boot)
library(BayesFactor)
library(pwr)
library(qgraph)
library(scales)


# Set global theme for consistent plots
theme_set(theme_minimal(base_size = 20) + 
          theme(
    plot.title = element_text(face = "bold", size = 26),    # adjust title size
    plot.subtitle = element_text(face = "bold", size = 24), # adjust subtitle size
    axis.title.x = element_text(face = "bold", size = 22),
    axis.title.y = element_text(face = "bold", size = 22),
    axis.text.x = element_text(face = "bold", size = 22, angle = 45, hjust = 1),
    legend.position = "bottom",
    strip.text = element_text(face = "bold"),
    panel.spacing.x = unit(1.5, "cm"),  # Horizontal spacing only
    panel.spacing.y = unit(1.5, "cm"),   # Vertical spacing only
    plot.margin = margin(20, 20, 20, 20, "pt")
    )
)


# Set seed for reproducibility
set.seed(123)

```


# Detailed Summary: "The Three Faces of Performance Measurement"

This article by Leif I. Solberg, Gordon Mosser, and Sharon McDonald (published in the Journal on Quality Improvement, 1997) explores the critical distinctions between three different purposes of healthcare performance measurement:

## The Three Faces of Performance Measurement

1. **Measurement for Improvement**: Focuses on collecting data to understand and enhance healthcare processes. This type of measurement is characterized by:
   - Small, frequent samples
   - Simple, easy-to-collect data
   - Internal audience (medical groups, QI teams, providers)
   - Purpose is to understand processes, motivate change, establish baselines, and evaluate changes
   - Confidentiality is vital to encourage honest assessment

2. **Measurement for Accountability**: Centers on reporting outcomes and results to external stakeholders. This type of measurement is characterized by:
   - Large samples over longer periods
   - Precise, validated measures
   - External audience (purchasers, payers, patients)
   - Purpose is to compare performance between providers or groups
   - Public disclosure is expected
   - Data must be highly reliable and standardized

3. **Measurement for Research**: Aims to develop new generalizable knowledge. This type of measurement is characterized by:
   - Complex, highly controlled data collection
   - Universal scope with rigorous methodology
   - Audience is the scientific community
   - Purpose is to generate new knowledge regardless of practical application
   - Requires controlling all variables and minimizing bias

## Key Insights from the Article

- The authors argue that confusing these three distinct purposes often leads to resistance from clinicians and ineffective measurement practices.

- When measurement for accountability is mixed with measurement for improvement, healthcare organizations may "game" the data or become defensive rather than focusing on genuine improvement.

- The article provides practical examples using urinary tract infection (UTI) treatment processes to demonstrate how differently measurement would be approached for each purpose.

- The authors present a seven-step process improvement model and argue that measurement should be targeted at three specific points in this process.

- The article concludes with recommendations for more effective measurement, including limiting the number of measures, ensuring they're meaningful to clinicians, making data collection easy, building baseline measures before implementing changes, and providing training and tools.

The authors emphasize that organizations must clearly distinguish between these three faces of measurement to avoid confusion, suspicion, and resistance, particularly as healthcare systems face increasing pressure for both accountability and quality improvement.



The authors outline several significant dangers of using accountability measures for improvement purposes:

1. **Poisoning the Improvement Effort**: They explicitly warn that "measurements collected for improvement purposes typically are not useful for external reporting and, if used for external reporting, may poison the improvement effort." This is one of their strongest cautions against mixing these purposes.

2. **Defensive Reactions Instead of Improvement**: When accountability measures are used, organizations tend to focus on defending their data rather than using it constructively for improvement. The authors note this creates a climate where "fear and blaming" dominate instead of focusing on systematic improvement.

3. **Gaming the System**: When data is collected for accountability but presented as improvement-focused, healthcare organizations may be tempted to "game" their data to appear better, rather than collecting honest information that would help them improve processes.

4. **Excessive Complexity and Burden**: Accountability measures are typically more complex, precise, and require larger samples than what's needed for improvement. Using these for improvement creates unnecessary work burden that can derail improvement efforts.

5. **Loss of Trust and Participation**: The authors describe how early measurement efforts at ICSI faced significant resistance from clinicians who feared that improvement data would be used for accountability or judgment. As noted in Sidebar 1, clinicians rejected a proposed measurement approach that felt like "a way to track individual clinician behavior."

6. **Inadequate Process Focus**: Accountability measures typically focus on outcomes rather than processes. The authors argue that improvement requires detailed process measurement, which accountability metrics rarely provide.

7. **Loss of Confidentiality**: The authors emphasize that improvement data needs to be protected and confidential to encourage honest assessment. When accountability is introduced, this protective environment is lost, hampering genuine improvement efforts.

The article presents these dangers not just as theoretical concerns but as actual problems encountered in their work with healthcare organizations. They specifically highlight that organizations involved in their projects learned to carefully separate these measurement purposes to make real progress on quality improvement.






